{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "import timeit\n",
    "start_time = timeit.default_timer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from sklearn.cluster import KMeans\n",
    "from scipy.optimize import minimize, least_squares\n",
    "from typing import Tuple\n",
    "import itertools as it\n",
    "from skimage.util import img_as_ubyte\n",
    "import skimage\n",
    "import torch\n",
    "import torch.nn.functional as func"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(True, True)"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#name = \"T_S04856\"\n",
    "# name = \"T_S04910\"\n",
    "# name = \"T_S04911\"\n",
    "# name = \"T_S04912\"\n",
    "name = \"T_S04923\"\n",
    "\n",
    "png_file = Path(f\"../../data/seathru/{name}.png\")\n",
    "tif_file = Path(f\"../../data/seathru/depth{name}.tif\")\n",
    "\n",
    "# png_file = Path(f\"../../data/seathru/D3/D3/linearPNG/{name}.png\")\n",
    "# tif_file = Path(f\"../../data/seathru/D3/D3/depth/depth{name}.tif\")\n",
    "png_file.exists(), tif_file.exists()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv2.imread(png_file) is None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "clusters = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "def uint8_2_double(array: np.ndarray):\n",
    "    return array.astype(np.float64) / 255.0\n",
    "\n",
    "def double_2_uint8(array: np.ndarray):\n",
    "    return (array * 255).astype(np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "def imshow(img: np.ndarray, color_channel=\"rgb\"):\n",
    "\n",
    "\n",
    "    if img.dtype == np.float64 and len(img.shape) == 3:\n",
    "        img = double_2_uint8(img)\n",
    "\n",
    "    if color_channel == \"bgr\":\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    elif color_channel == \"hsv\":\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_HSV2RGB)\n",
    "\n",
    "    plt.imshow(img)\n",
    "\n",
    "    if len(img.shape) == 2:\n",
    "        plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "png = uint8_2_double(cv2.imread(png_file))\n",
    "height, width, _ = png.shape\n",
    "\n",
    "##imshow(png, color_channel=\"bgr\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('float64')"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "png.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "tif_image = Image.open(tif_file)\n",
    "tif = np.array(tif_image)\n",
    "tif = cv2.resize(tif, (width, height),  interpolation = cv2.INTER_NEAREST)\n",
    "\n",
    "##imshow(tif)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1596, 2400, 3), (1596, 2400))"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "png.shape, tif.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(np.float32(1.0321687), np.float32(2.0977757))"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tif.min(), tif.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3830400,)"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tif_flat = tif.flatten()\n",
    "\n",
    "tif_flat.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Backscatter Estimation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "# kmeans = KMeans(n_clusters=clusters, random_state=0, n_init=\"auto\").fit(tif_flat[tif_flat != 0].reshape(-1, 1))\n",
    "# labels = np.zeros(tif_flat.shape, dtype=np.uint8)\n",
    "# labels[tif_flat != 0] = kmeans.labels_\n",
    "# labels[tif_flat == 0] = 255 # Use 255 to represent nan\n",
    "# means = np.array(kmeans.cluster_centers_).flatten()\n",
    "# means_args = np.argsort(means)\n",
    "\n",
    "# labels_new = np.zeros_like(labels)\n",
    "# labels_new[labels == 255] = clusters + 1\n",
    "\n",
    "# for current_label in range(clusters):\n",
    "#     new_label = np.nonzero(means_args == current_label)[0]\n",
    "#     labels_new[labels == current_label] = new_label\n",
    "\n",
    "# labels = labels_new.reshape((height, width))\n",
    "# #imshow(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, edges = np.histogram(tif_flat, clusters)\n",
    "\n",
    "labels = np.zeros(tif.shape, dtype=np.uint8)\n",
    "for i in range(clusters + 1):\n",
    "    labels[np.logical_and(tif <= edges[i], labels == 0)] = i\n",
    "\n",
    "##imshow(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "UniqueCountsResult(values=array([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10], dtype=uint8), counts=array([624129, 367726,  80555,  11589, 263087, 699030, 563987, 637811,\n",
       "       473182, 109304]))"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique_counts(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "dark_pixels = []\n",
    "z_values = []\n",
    "\n",
    "for i in range(1, clusters + 1):\n",
    "    mask = labels == i\n",
    "    filtered = png * mask[:, :, np.newaxis]\n",
    "\n",
    "    b = png[:, :, 0]\n",
    "    g = png[:, :, 1]\n",
    "    r = png[:, :, 2]\n",
    "\n",
    "    b_filtered = b[mask].flatten()\n",
    "    g_filtered = g[mask].flatten()\n",
    "    r_filtered = r[mask].flatten()\n",
    "\n",
    "    pixels = np.array([[b,g,r] for b,g,r in zip(b_filtered, g_filtered , r_filtered)])\n",
    "    idx = np.nonzero(np.all(pixels <= np.percentile(pixels, 1, axis=0), axis=1))\n",
    "    selected_pixels = pixels[idx]\n",
    "\n",
    "    filtered_tif = tif[mask].flatten()\n",
    "    z = filtered_tif[idx]\n",
    "\n",
    "    dark_pixels.extend(selected_pixels.tolist())\n",
    "    z_values.extend(z.tolist())\n",
    "\n",
    "dark_pixels = np.array(dark_pixels)\n",
    "z_values = np.array(z_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([    5,     6,     7, ..., 84615, 84616, 84957], shape=(1167,)),)"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9.148796018443973e-06"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(idx) / pixels.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[False, False,  True],\n",
       "        [False, False,  True],\n",
       "        [False, False, False],\n",
       "        ...,\n",
       "        [False, False, False],\n",
       "        [False, False, False],\n",
       "        [False, False, False]], shape=(109304, 3)),\n",
       " array([0.02352941, 0.03137255, 0.00392157]),\n",
       " array([0.01960784, 0.02745098, 0.00392157]))"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pixels <= np.percentile(pixels, 1, axis=0), pixels[0],  np.percentile(pixels, 1, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1596, 2400, 3), 3830400)"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "png.shape, 1596 * 2400"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.01442094820384294, (55238,))"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dark_pixels.shape[0] / (1596 * 2400), z_values.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(np.float32(1.0321687), np.float32(2.0977757))"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tif.min(), tif.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.1349144 , 1.13483131, 1.13463235, ..., 2.01135969, 2.01256084,\n",
       "       2.01059484], shape=(55238,))"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimate_backscatter(B_inf: float, beta_B: float, J_prime: float, beta_D_prime: float, z):\n",
    "    return B_inf * (1 - np.exp(- beta_B * z)) + (J_prime * np.exp(- beta_D_prime * z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize_estimate_backscatter(arguments: Tuple[float, float, float, float], B_hat: np.ndarray, z: np.ndarray):\n",
    "    B_inf, beta_B, J_prime, beta_D_prime = arguments\n",
    "\n",
    "    return estimate_backscatter(B_inf, beta_B, J_prime, beta_D_prime, z) - B_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "def leastsquares_estimate_backscatter(dark_pixels: np.ndarray, z_values: np.ndarray, color_channel: int, starts=1):\n",
    "    lo = np.array([0, 0, 0, 0])\n",
    "    hi = np.array([1, 5, 1, 5])\n",
    "\n",
    "    best_params = None\n",
    "    best_loss = None\n",
    "\n",
    "    for _ in range(starts):\n",
    "        starting_point = np.random.random_sample(4)\n",
    "        starting_point[1] *= 5\n",
    "        starting_point[3] *= 5\n",
    "\n",
    "        print(starting_point)\n",
    "\n",
    "        try:\n",
    "            result = least_squares(optimize_estimate_backscatter, starting_point, args=(dark_pixels[:, color_channel], z_values), loss='soft_l1', bounds=(lo, hi))\n",
    "        except ValueError:\n",
    "            continue\n",
    "        \n",
    "        params = result.x\n",
    "        loss = np.linalg.norm(optimize_estimate_backscatter(params, dark_pixels[:, color_channel], z_values))\n",
    "\n",
    "        print(loss, params)\n",
    "\n",
    "        if best_loss is None or loss < best_loss:\n",
    "            best_params = params\n",
    "            best_loss = loss\n",
    "            \n",
    "    return best_params, best_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dsssdfsd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.00392157, 0.01176471, 0.        ],\n",
       "       [0.00392157, 0.01176471, 0.        ],\n",
       "       [0.00392157, 0.01176471, 0.        ],\n",
       "       ...,\n",
       "       [0.01960784, 0.02745098, 0.00392157],\n",
       "       [0.01960784, 0.02745098, 0.00392157],\n",
       "       [0.01960784, 0.02745098, 0.00392157]], shape=(55238, 3))"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dark_pixels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.19273326 1.11985487 0.66827728 2.45833801]\n",
      "0.758424514943741 [1.00000000e+00 7.30696394e-03 1.59074729e-35 4.99286277e+00]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([1.00000000e+00, 7.30696394e-03, 1.59074729e-35, 4.99286277e+00]),\n",
       " np.float64(0.758424514943741))"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b_args, loss = leastsquares_estimate_backscatter(dark_pixels, z_values, 0)\n",
    "\n",
    "b_args, loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.42317271 3.46860837 0.74297095 0.3151832 ]\n",
      "0.8817816163052851 [9.99999997e-01 1.19615775e-02 1.25972728e-29 4.86621841e+00]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([9.99999997e-01, 1.19615775e-02, 1.25972728e-29, 4.86621841e+00]),\n",
       " np.float64(0.8817816163052851))"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g_args, loss = leastsquares_estimate_backscatter(dark_pixels, z_values, 1)\n",
    "\n",
    "g_args, loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.67937576 4.22025035 0.60441658 4.28155704]\n",
      "0.3789708709319066 [9.99999979e-01 1.62139613e-03 1.71035608e-82 4.99960514e+00]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([9.99999979e-01, 1.62139613e-03, 1.71035608e-82, 4.99960514e+00]),\n",
       " np.float64(0.3789708709319066))"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r_args, loss = leastsquares_estimate_backscatter(dark_pixels, z_values, 2)\n",
    "\n",
    "r_args, loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "B_b = estimate_backscatter(b_args[0], b_args[1], b_args[2], b_args[3], tif_flat).reshape((height, width))\n",
    "\n",
    "#imshow(B_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "B_g = estimate_backscatter(g_args[0], g_args[1], g_args[2], g_args[3], tif_flat).reshape((height, width))\n",
    "\n",
    "#imshow(B_g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "B_r = estimate_backscatter(r_args[0], r_args[1], r_args[2], r_args[3], tif_flat).reshape((height, width))\n",
    "\n",
    "#imshow(B_r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "backscatter = np.zeros((height, width, 3), dtype=np.float64)\n",
    "\n",
    "backscatter[:, :, 0] = B_b\n",
    "backscatter[:, :, 1] = B_g\n",
    "backscatter[:, :, 2] = B_r\n",
    "\n",
    "#imshow(backscatter / backscatter.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0.02745098, 0.04705882, 0.00784314],\n",
       "        [0.02745098, 0.04705882, 0.00784314],\n",
       "        [0.02745098, 0.04313725, 0.00784314],\n",
       "        ...,\n",
       "        [0.05882353, 0.09411765, 0.01960784],\n",
       "        [0.05882353, 0.09411765, 0.01960784],\n",
       "        [0.05882353, 0.09411765, 0.01960784]],\n",
       "\n",
       "       [[0.02352941, 0.03921569, 0.00784314],\n",
       "        [0.02352941, 0.03529412, 0.00392157],\n",
       "        [0.02352941, 0.03529412, 0.00392157],\n",
       "        ...,\n",
       "        [0.05882353, 0.09803922, 0.01960784],\n",
       "        [0.05882353, 0.09803922, 0.01960784],\n",
       "        [0.05882353, 0.09803922, 0.01960784]],\n",
       "\n",
       "       [[0.02352941, 0.03529412, 0.00392157],\n",
       "        [0.01960784, 0.03137255, 0.00392157],\n",
       "        [0.02352941, 0.03529412, 0.00392157],\n",
       "        ...,\n",
       "        [0.05490196, 0.09411765, 0.01960784],\n",
       "        [0.05490196, 0.09411765, 0.01960784],\n",
       "        [0.05490196, 0.09411765, 0.01960784]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[0.04705882, 0.0745098 , 0.01176471],\n",
       "        [0.04313725, 0.0745098 , 0.01568627],\n",
       "        [0.03137255, 0.05490196, 0.01176471],\n",
       "        ...,\n",
       "        [0.04313725, 0.07058824, 0.01176471],\n",
       "        [0.04313725, 0.07058824, 0.01176471],\n",
       "        [0.04313725, 0.07058824, 0.01176471]],\n",
       "\n",
       "       [[0.04313725, 0.06666667, 0.01176471],\n",
       "        [0.03921569, 0.0627451 , 0.01176471],\n",
       "        [0.03921569, 0.06666667, 0.01176471],\n",
       "        ...,\n",
       "        [0.04705882, 0.0745098 , 0.01568627],\n",
       "        [0.04705882, 0.0745098 , 0.01568627],\n",
       "        [0.04705882, 0.0745098 , 0.01568627]],\n",
       "\n",
       "       [[0.04313725, 0.0627451 , 0.01176471],\n",
       "        [0.04705882, 0.07843137, 0.01176471],\n",
       "        [0.05882353, 0.10196078, 0.01960784],\n",
       "        ...,\n",
       "        [0.05098039, 0.08235294, 0.01568627],\n",
       "        [0.05098039, 0.08235294, 0.01568627],\n",
       "        [0.05098039, 0.08235294, 0.01568627]]], shape=(1596, 2400, 3))"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "png"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "direct_signal = png - backscatter\n",
    "\n",
    "# sig_min_b = direct_signal[:, :, 0].min()\n",
    "# sig_min_g = direct_signal[:, :, 1].min()\n",
    "# sig_min_r = direct_signal[:, :, 2].min()\n",
    "\n",
    "# if sig_min_b > 0:\n",
    "#     sig_min_b = 0\n",
    "\n",
    "# if sig_min_g > 0:\n",
    "#     sig_min_g = 0\n",
    "\n",
    "# if sig_min_r > 0:\n",
    "#     sig_min_r = 0\n",
    "\n",
    "# direct_signal[:, :, 0] = direct_signal[:, :, 0] - sig_min_b\n",
    "# direct_signal[:, :, 1] = direct_signal[:, :, 1] - sig_min_g\n",
    "# direct_signal[:, :, 2] = direct_signal[:, :, 2] - sig_min_r\n",
    "\n",
    "direct_signal = np.clip(direct_signal, 0, 1)\n",
    "\n",
    "#imshow(direct_signal, color_channel=\"bgr\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0.01327015, 0.02394968, 0.00467894],\n",
       "        [0.01327015, 0.02394968, 0.00467894],\n",
       "        [0.01326454, 0.02001901, 0.00467768],\n",
       "        ...,\n",
       "        [0.045357  , 0.07216751, 0.01660387],\n",
       "        [0.04535898, 0.07217072, 0.01660432],\n",
       "        [0.04536442, 0.07217955, 0.01660554]],\n",
       "\n",
       "       [[0.00934858, 0.01610654, 0.00467894],\n",
       "        [0.00934858, 0.01218497, 0.00075737],\n",
       "        [0.00934297, 0.01217587, 0.00075611],\n",
       "        ...,\n",
       "        [0.045357  , 0.07608907, 0.01660387],\n",
       "        [0.04535898, 0.07609229, 0.01660432],\n",
       "        [0.04536442, 0.07610112, 0.01660554]],\n",
       "\n",
       "       [[0.00935124, 0.01218929, 0.00075797],\n",
       "        [0.00542967, 0.00826772, 0.00075797],\n",
       "        [0.00934579, 0.01218045, 0.00075674],\n",
       "        ...,\n",
       "        [0.04143536, 0.07216739, 0.01660386],\n",
       "        [0.04144019, 0.07217523, 0.01660494],\n",
       "        [0.04144311, 0.07217997, 0.0166056 ]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[0.03596798, 0.0564182 , 0.00929299],\n",
       "        [0.03204641, 0.0564182 , 0.01321456],\n",
       "        [0.02028065, 0.03680864, 0.00929275],\n",
       "        ...,\n",
       "        [0.03180008, 0.05209626, 0.00923784],\n",
       "        [0.03180567, 0.05210535, 0.0092391 ],\n",
       "        [0.03181031, 0.0521129 , 0.00924014]],\n",
       "\n",
       "       [[0.0320461 , 0.04857455, 0.00929292],\n",
       "        [0.02812453, 0.04465299, 0.00929292],\n",
       "        [0.02812476, 0.04857492, 0.00929297],\n",
       "        ...,\n",
       "        [0.03572013, 0.05601538, 0.01315908],\n",
       "        [0.03572552, 0.05602413, 0.01316028],\n",
       "        [0.03572843, 0.05602886, 0.01316093]],\n",
       "\n",
       "       [[0.03204611, 0.044653  , 0.00929292],\n",
       "        [0.03596768, 0.06033927, 0.00929292],\n",
       "        [0.04773243, 0.08386876, 0.01713607],\n",
       "        ...,\n",
       "        [0.03964115, 0.06385761, 0.01315895],\n",
       "        [0.03964664, 0.06386653, 0.01316018],\n",
       "        [0.03964963, 0.06387139, 0.01316085]]], shape=(1596, 2400, 3))"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "direct_signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt.imshow((png < backscatter)[:, :, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1596, 2400, 3)"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.savez_compressed(f\"./output/DS_{name}.npz\", direct_signal=direct_signal.astype(np.float32))\n",
    "\n",
    "direct_signal.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Attenuation Coefficient Estimation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Coarse Estimate of $\\beta_c^D(z)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "epsilon_percent = 0.1\n",
    "convergence_threshold = 0.001\n",
    "f = 2.0\n",
    "p = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float32(0.1065607)"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epsilon = (tif.max() - tif_flat[tif_flat != 0].min()) * epsilon_percent\n",
    "\n",
    "epsilon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_tensor(tensor: torch.Tensor, top: int, right: int, left: int, bottom: int) -> torch.Tensor:\n",
    "    dim = len(tensor.shape)\n",
    "\n",
    "    if len(tensor.shape) == 2:\n",
    "        tensor = tensor[:, :, None]\n",
    "\n",
    "    height, width, channels = tensor.shape\n",
    "\n",
    "    new_height = height + top + bottom\n",
    "    new_width = width + right + left\n",
    "\n",
    "    bottom_idx = new_height - bottom\n",
    "    right_idx = new_width - right\n",
    "\n",
    "    padded = torch.zeros((new_height, new_width, channels), device=device)\n",
    "    padded[top:bottom_idx, left:right_idx, :] = tensor\n",
    "\n",
    "    if dim == 2:\n",
    "        return padded[:, :]\n",
    "    else:\n",
    "        return padded\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_direction(tensor: torch.Tensor):\n",
    "    if len(tensor.shape) == 2:\n",
    "        tensor = tensor[:, :, None]\n",
    "\n",
    "    height, width, channels = tensor.shape\n",
    "\n",
    "    direction = torch.zeros((height + 2, width + 2, 4, channels), device=device)\n",
    "    direction[:, :, 0, :] = pad_tensor(tensor, 2, 1, 1, 0)\n",
    "    direction[:, :, 1, :] = pad_tensor(tensor, 1, 2, 0, 1)\n",
    "    direction[:, :, 2, :] = pad_tensor(tensor, 0, 1, 1, 2)\n",
    "    direction[:, :, 3, :] = pad_tensor(tensor, 1, 0, 2, 1)\n",
    "\n",
    "    return direction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "# direct_signal_tensor = pad_tensor(torch.as_tensor(direct_signal, device=device), 1, 1, 1, 1)\n",
    "# a_values_tensor = direct_signal_tensor\n",
    "# depths_tensor = torch.as_tensor(tif, device=device)\n",
    "# diff_depth_map_tensor = torch.abs(torch.dstack([pad_tensor(depths_tensor, 1, 1, 1, 1)] * 4) - pad_direction(depths_tensor).squeeze())\n",
    "# softmax = func.softmax(-diff_depth_map_tensor, dim=-1)\n",
    "# weights = torch.stack([softmax] * 3, dim=-1)\n",
    "\n",
    "# for i in range(100):\n",
    "#     a_values_tensor = pad_direction(a_values_tensor[1:-1, 1:-1, :])\n",
    "#     a_values_tensor = torch.sum(weights * a_values_tensor, axis=2)\n",
    "#     a_values_tensor = (1 - p) * a_values_tensor + p * direct_signal_tensor\n",
    "\n",
    "# a_values_tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a_values = a_values_tensor[1:-1, 1:-1, :].detach().cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imshow(a_values[:, :, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imshow(a_values[:, :, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imshow(a_values[:, :, 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.7143973\n"
     ]
    }
   ],
   "source": [
    "local_illuminant_map = f * a_values\n",
    "\n",
    "print(local_illuminant_map.max())\n",
    "#imshow(local_illuminant_map / local_illuminant_map.max(), color_channel=\"bgr\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolution Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "from depthwise_color_consistency import depthwise_color_consistency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "direct_signal_tensor = pad_tensor(torch.as_tensor(direct_signal, device=device), 1, 1, 1, 1)\n",
    "a_values_tensor = direct_signal_tensor\n",
    "depths_tensor = torch.as_tensor(tif, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_32 = direct_signal.astype(np.float32)\n",
    "depth_32 = tif.astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_c_new = depthwise_color_consistency(\n",
    "    2000,\n",
    "    p,\n",
    "    depth_32,\n",
    "    ds_32\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "# local_illuminant_map = f * a_values\n",
    "\n",
    "# print(local_illuminant_map.max())\n",
    "# #imshow(local_illuminant_map / local_illuminant_map.max(), color_channel=\"bgr\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.736712098121643\n"
     ]
    }
   ],
   "source": [
    "local_illuminant_map = f * a_c_new.astype(np.float64)\n",
    "\n",
    "print(local_illuminant_map.max())\n",
    "#imshow(local_illuminant_map / local_illuminant_map.max(), color_channel=\"bgr\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EVERYTHING ELSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([9.24348091e-29, 1.07566835e-28, 1.21702619e-28, ...,\n",
       "        1.73331380e+00, 1.73347449e+00, 1.73671210e+00], shape=(11491200,)),\n",
       " np.float64(0.0))"
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sort(local_illuminant_map.flatten()), (local_illuminant_map[:, :, 0] <= 0).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "beta_d_coarse = np.zeros_like(local_illuminant_map)\n",
    "\n",
    "beta_d_coarse[:, :, 0] = - np.log(local_illuminant_map[:, :, 0]) / tif\n",
    "beta_d_coarse[:, :, 1] = - np.log(local_illuminant_map[:, :, 1]) / tif\n",
    "beta_d_coarse[:, :, 2] = - np.log(local_illuminant_map[:, :, 2]) / tif\n",
    "\n",
    "beta_min = beta_d_coarse.min()\n",
    "beta_max = beta_d_coarse.max() - beta_min\n",
    "#imshow((beta_d_coarse - beta_min) / beta_max, color_channel=\"bgr\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imshow(beta_d_coarse[:, :, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([-0.16815483, -0.16807329, -0.16797109, ..., 46.84662479,\n",
       "        46.91694157, 47.55386221], shape=(3830400,)),\n",
       " np.float64(0.0),\n",
       " np.float64(0.0004848057644110276))"
      ]
     },
     "execution_count": 232,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sort(beta_d_coarse[:, :, 0].flatten()), np.isnan(beta_d_coarse[:,:,0].flatten()).mean(), (beta_d_coarse[:,:,0].flatten() < 0).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imshow(beta_d_coarse[:, :, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imshow(beta_d_coarse[:, :, 2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Refined Estimate of $\\beta_c^D(z)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_beta_D(a: float, b: float, c: float, d: float, z: np.ndarray) -> np.ndarray:\n",
    "    return a * np.exp(b * z) + c * np.exp(d * z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize_compute_beta_D(args: Tuple[float, float, float, float], E: np.ndarray, z: np.ndarray) -> np.ndarray[float]:\n",
    "    a, b, c, d = args\n",
    "    beta_D = compute_beta_D(a, b, c, d, z)\n",
    "    z_hat = -np.log(E) / beta_D\n",
    "\n",
    "    return (z - z_hat).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_beta_D_args(local_illuminant_map: np.ndarray, depths: np.ndarray, color_channel: int):\n",
    "    a = - 0.5 * ((np.log(local_illuminant_map[:, :, color_channel]) ** 2).sum() / (depths * np.log(local_illuminant_map[:, :, color_channel])).sum() + (depths ** 2 * np.log(local_illuminant_map[:, :, color_channel] ** 3)).sum() / (depths * np.log(local_illuminant_map[:, :, color_channel]) ** 2).sum())\n",
    "    c = a\n",
    "\n",
    "    num_sum_1 = (np.log(local_illuminant_map[:, :, color_channel]) ** 2 * depths).sum()\n",
    "    denom_sum_1 = (np.log(local_illuminant_map[:, :, color_channel]) * (depths ** 2)).sum()\n",
    "\n",
    "    num_sum_2 = (depths ** 3 * np.log(local_illuminant_map[:, :, color_channel]) ** 3).sum()\n",
    "    denom_sum_2 = (depths ** 2 * np.log(local_illuminant_map[:, :, color_channel]) ** 2).sum()\n",
    "\n",
    "    b = -(num_sum_1) / (denom_sum_1 * a) + num_sum_2 / denom_sum_2\n",
    "    d = -(num_sum_1) / (denom_sum_1 * c) + num_sum_2 / denom_sum_2\n",
    "\n",
    "    params = a, b, c, d\n",
    "\n",
    "    # lo = np.array([0, -np.inf, 0, -np.inf])\n",
    "    # hi = np.array([np.inf, 0, np.inf, 0])\n",
    "\n",
    "    # result = least_squares(optimize_compute_beta_D, params, args=(local_illuminant_map[:, :, color_channel], depths), bounds=(lo, hi))\n",
    "    # params = result.x\n",
    "\n",
    "    return params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(np.float64(1.933982395957957),\n",
       " np.float64(-9.866615532558527),\n",
       " np.float64(1.933982395957957),\n",
       " np.float64(-9.866615532558527))"
      ]
     },
     "execution_count": 238,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b_args = compute_beta_D_args(local_illuminant_map, tif, 0)\n",
    "\n",
    "b_args\n",
    "\n",
    "# (np.float32(0.9593941),\n",
    "# np.float32(-1.2186562),\n",
    "# np.float32(0.9593941),\n",
    "# np.float32(-1.2186562))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(np.float64(1.782019794764382),\n",
       " np.float64(-17.634124176038267),\n",
       " np.float64(1.782019794764382),\n",
       " np.float64(-17.634124176038267))"
      ]
     },
     "execution_count": 239,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g_args = compute_beta_D_args(local_illuminant_map, tif, 1)\n",
    "\n",
    "g_args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(np.float64(1.8546333005067592),\n",
       " np.float64(-5.896979937133003),\n",
       " np.float64(1.8546333005067592),\n",
       " np.float64(-5.896979937133003))"
      ]
     },
     "execution_count": 240,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r_args = compute_beta_D_args(local_illuminant_map, tif, 2)\n",
    "\n",
    "r_args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(np.float64(134503020019.75331),\n",
       " np.float64(8.56972974632974e+17),\n",
       " np.float64(80502602.45996897))"
      ]
     },
     "execution_count": 241,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b_loss = np.linalg.norm(optimize_compute_beta_D(b_args, local_illuminant_map[:, :, 0], tif))\n",
    "g_loss = np.linalg.norm(optimize_compute_beta_D(g_args, local_illuminant_map[:, :, 1], tif))\n",
    "r_loss = np.linalg.norm(optimize_compute_beta_D(r_args, local_illuminant_map[:, :, 2], tif))\n",
    "\n",
    "b_loss, g_loss, r_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "beta_d = np.zeros_like(local_illuminant_map)\n",
    "\n",
    "beta_d[:, :, 0] = compute_beta_D(b_args[0], b_args[1], b_args[2], b_args[3], tif)\n",
    "beta_d[:, :, 1] = compute_beta_D(g_args[0], g_args[1], g_args[2], g_args[3], tif)\n",
    "beta_d[:, :, 2] = compute_beta_D(r_args[0], r_args[1], r_args[2], r_args[3], tif)\n",
    "\n",
    "beta_d_min = beta_d.min()\n",
    "beta_d_max = beta_d.max() - beta_d_min\n",
    "#imshow((beta_d - beta_d_min) / beta_d_max, color_channel=\"bgr\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0000000083221916 1.0000000000000007 1.0000330062727296\n",
      "1.0001508015018783 1.0000000458067202 1.0087401511070333\n"
     ]
    }
   ],
   "source": [
    "J = np.zeros_like(direct_signal)\n",
    "\n",
    "print(np.exp(beta_d[:, :, 0] * tif).min(), np.exp(beta_d[:, :, 1] * tif).min(), np.exp(beta_d[:, :, 2] * tif).min())\n",
    "print(np.exp(beta_d[:, :, 0] * tif).max(), np.exp(beta_d[:, :, 1] * tif).max(), np.exp(beta_d[:, :, 2] * tif).max())\n",
    "\n",
    "J[:, :, 0] = direct_signal[:, :, 0] * np.exp(beta_d[:, :, 0] * tif)\n",
    "J[:, :, 1] = direct_signal[:, :, 1] * np.exp(beta_d[:, :, 1] * tif)\n",
    "J[:, :, 2] = direct_signal[:, :, 2] * np.exp(beta_d[:, :, 2] * tif)\n",
    "\n",
    "# J[:, :, 0] = J[:, :, 0] / J[:, :, 0].max()\n",
    "# J[:, :, 1] = J[:, :, 1] / J[:, :, 1].max()\n",
    "# J[:, :, 2] = J[:, :, 2] / J[:, :, 2].max()\n",
    "\n",
    "J = J / J.max()\n",
    "\n",
    "#imshow(J, color_channel=\"bgr\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imshow(J[:, :, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imshow(J[:, :, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imshow(J[:, :, 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [],
   "source": [
    "J_8 = double_2_uint8(J)\n",
    "\n",
    "#imshow(J, color_channel=\"bgr\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gray_world(image):\n",
    "    \"\"\"\n",
    "    White balance image using Gray-world algorithm.\n",
    "    \"\"\"\n",
    "    access_gw = ((image * (image.mean() / image.mean(axis=(0, 1))))\n",
    "             .clip(0, 255))\n",
    "    \n",
    "    return access_gw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale(img):\n",
    "    return img_as_ubyte((img - np.min(img)) / (np.max(img) - np.min(img)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [],
   "source": [
    "J_gray_world = scale(gray_world(J_8.astype(np.float64)))\n",
    "\n",
    "#imshow(J_gray_world, color_channel=\"bgr\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [],
   "source": [
    "def white_patch(image, percentile=50):\n",
    "    \"\"\"\n",
    "    Adjust the color balance of an image based on the white patch method.\n",
    "    \"\"\"\n",
    "    access_wp2 = ((image*1.0 / np.percentile(image, percentile, \n",
    "                                                         axis=(0, 1)))\n",
    "                              .clip(0, 1))\n",
    "    return access_wp2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pcts = [100, 99, 98, 97]\n",
    "# op_wp = J_8*1.0 / J_8.max(axis=(0,1))\n",
    "# fig, axs = plt.subplots(2, 2, figsize=(8, 8))\n",
    "# axs = axs.flatten()\n",
    "\n",
    "# # for idx, pct in enumerate(pcts):\n",
    "# #     op_wp2 = img_as_ubyte(white_patch(op_wp, pct))\n",
    "# #     axs[idx].imshow(cv2.cvtColor(op_wp2, cv2.COLOR_BGR2RGB))\n",
    "# #     axs[idx].set_title(f'{pct}th percentile')\n",
    "\n",
    "# # plt.tight_layout()\n",
    "# # plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [],
   "source": [
    "op_wp = img_as_ubyte(J_8*1.0 / J_8.max(axis=(0,1)))\n",
    "img = img_as_ubyte((0.8 * white_patch(op_wp, 100) + 0.2 * white_patch(op_wp, 99)))\n",
    "\n",
    "#imshow(img, color_channel=\"bgr\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [],
   "source": [
    "hsv = uint8_2_double(cv2.cvtColor(img, cv2.COLOR_BGR2HSV))\n",
    "hsv[:, :, 1] *= 2\n",
    "hsv[:, :, 2] *= 1.8\n",
    "\n",
    "hsv[hsv[:, :, 1] >= 1, 1] = 1\n",
    "hsv[hsv[:, :, 2] >= 1, 2] = 1\n",
    "\n",
    "#imshow(hsv, color_channel=\"hsv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_adjusted = cv2.cvtColor(img_as_ubyte(hsv), cv2.COLOR_HSV2BGR)\n",
    "\n",
    "#imshow(img_adjusted, color_channel=\"bgr\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_gamma = skimage.exposure.adjust_gamma(img_adjusted, gamma=0.8)\n",
    "\n",
    "#imshow(img_gamma, color_channel=\"bgr\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_hist = skimage.exposure.equalize_adapthist(img_gamma)\n",
    "\n",
    "imshow(img_hist, color_channel=\"bgr\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 258,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv2.imwrite(\"output/crutchfield_perry_final.png\", img_as_ubyte(img_hist))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "42.63029922591522"
      ]
     },
     "execution_count": 259,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "timeit.default_timer() - start_time"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
